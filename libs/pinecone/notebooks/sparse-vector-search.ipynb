{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: pinecone 6.0.2 does not provide the extra 'async'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-pinecone pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credentials\n",
    "Create a new Pinecone account, or sign into your existing one, and create an API key to use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesbriggs/Documents/pointman/pinecone/aurelio-langchain-pinecone/langchain-pinecone/libs/pinecone/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "from pinecone import Pinecone\n",
    "\n",
    "if not os.getenv(\"PINECONE_API_KEY\"):\n",
    "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")\n",
    "\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "Before initializing our vector store, let's connect to a Pinecone index. If one named index_name doesn't exist, it will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index `langchain-sparse-vector-search` host: https://langchain-sparse-vector-search-yrrgefy.svc.aped-4627-b74a.pinecone.io\n"
     ]
    }
   ],
   "source": [
    "index_name = \"langchain-sparse-vector-search\"  # change if desired\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index_for_model(\n",
    "        name=index_name,\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\",\n",
    "        embed={\n",
    "            \"model\":\"pinecone-sparse-english-v0\",\n",
    "            \"field_map\":{\"text\": \"chunk_text\"},\n",
    "            \"metric\": \"dotproduct\",\n",
    "            \"read_parameters\": {},\n",
    "            \"write_parameters\": {}\n",
    "        }\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "print(f\"Index `{index_name}` host: {index.config.host}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our sparse embedding model we use [`pinecone-sparse-english-v0`](https://docs.pinecone.io/models/pinecone-sparse-english-v0), we initialize it like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeSparseEmbeddings\n",
    "\n",
    "sparse_embeddings = PineconeSparseEmbeddings(model=\"pinecone-sparse-english-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our Pinecone index and embedding model are both ready, we can initialize our sparse vector store in LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeSparseVectorStore\n",
    "\n",
    "vector_store = PineconeSparseVectorStore(index=index, embedding=sparse_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage vector store\n",
    "Once you have created your vector store, we can interact with it by adding and deleting different items.\n",
    "\n",
    "#### Add items to vector store\n",
    "We can add items to our vector store by using the `add_documents` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8c6485d5-4d7c-4953-a0b3-8661116038f5',\n",
       " '168b57fe-f566-4f9e-b76e-5186bee2f201',\n",
       " '404fa844-4e47-4c25-a071-4807e5e2c849',\n",
       " '89678148-b650-4307-9b46-d5ee3be96132',\n",
       " '95463694-4403-4900-a541-839b6212461f',\n",
       " '8e7be680-b175-485e-866b-0eb7f59f42f0',\n",
       " 'b47e15b9-9e37-4402-aa24-94cc05bbc53e',\n",
       " '606e0db6-73dd-4805-844a-4cee759c9ec5',\n",
       " '1ac1723f-1e9f-473f-87af-d0df94b03e52',\n",
       " '21bbafe3-ecc9-4e55-9ffc-0ed45f48eff1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "        metadata={\"source\": \"social\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "        metadata={\"source\": \"news\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "        metadata={\"source\": \"social\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "        metadata={\"source\": \"news\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "        metadata={\"source\": \"social\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "        metadata={\"source\": \"website\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"The top 10 soccer players in the world right now.\",\n",
    "        metadata={\"source\": \"website\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "        metadata={\"source\": \"social\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "        metadata={\"source\": \"news\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "        metadata={\"source\": \"social\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete items from vector store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can delete records from our vector store using the `delete` method, providing it with a list of document IDs to delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.delete(ids=[uuids[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the Vector Store\n",
    "\n",
    "Once we have loaded our documents into the vector store we're most likely ready to begin querying. There are various method for doing this in LangChain.\n",
    "\n",
    "First, we'll see how to perform a simple vector search by querying our `vector_store` directly via the `similarity_search` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
      "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n",
      "* Is the new iPhone worth the price? Read this review to find out. [{'source': 'website'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\"I'm building a new LangChain project!\", k=3)\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add metadata filtering to our query to limit our search based on various criteria. Let's try limiting the sources to only include tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
      "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n",
      "* I had chocalate chip pancakes and scrambled eggs for breakfast this morning. [{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"I'm building a new LangChain project!\",\n",
    "    k=3,\n",
    "    filter={\"source\": \"tweet\"},\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing these results, we can see that our first query returned t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Similarity search with score\n",
    "\n",
    "We can also search and return both the response and the similarity as a list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=4.640625] The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees. [{'source': 'news'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    \"Will it be hot tomorrow?\", k=3, filter={\"source\": \"news\"}\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query by turning into retriever\n",
    "You can also transform the vector store into a retriever for easier usage in your chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakit/customers/aurelio/langchain-pinecone/libs/pinecone/.venv/lib/python3.10/site-packages/langchain_core/vectorstores/base.py:1077: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='38587162-422c-41aa-bad9-8dd6c8025d90', metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.'), 2.3984375)]\n",
      "  self.vectorstore.similarity_search_with_relevance_scores(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='38587162-422c-41aa-bad9-8dd6c8025d90', metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 1, \"score_threshold\": 0.5},\n",
    ")\n",
    "retriever.invoke(\"Stealing from the bank is a crime\", filter={\"source\": \"news\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
