{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone VectorStore Async Lifecycle Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a87a232",
   "metadata": {},
   "source": [
    "This notebook demonstrates two ways to manage the async Pinecone client that backs `PineconeVectorStore`:\n",
    "\n",
    "1. Letting the store handle connections automatically by using `async with` (no manual close).\n",
    "2. Closing the session yourself with `await store.aclose()` when you want deterministic cleanup.\n",
    "\n",
    "Each section below walks through one of these approaches so you can run the cells and observe that the store no longer throws `RuntimeError: Session is closed` after back-to-back async calls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5476cf73",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Install the project dependencies (see the repository README).\n",
    "- Create or reuse a Pinecone serverless index that matches the dimensionality of your embeddings.\n",
    "- Export the credentials before running: `export PINECONE_API_KEY=...` and optionally `export PINECONE_INDEX_NAME=...`.\n",
    "- Provide an embedding model; this example uses `langchain-openai` but you can swap in any `Embeddings` implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decd0762",
   "metadata": {},
   "source": [
    "## Load Environment Variables\n",
    "If you keep credentials in a `.env` file, the next cell loads it so you do not have to export environment variables manually each time. Feel free to skip this step if you prefer to set variables in your shell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7f2f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7192937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"Set the PINECONE_API_KEY environment variable before running this notebook.\")\n",
    "\n",
    "INDEX_NAME = os.environ.get(\"PINECONE_INDEX_NAME\", \"YOUR_INDEX_NAME\")\n",
    "if INDEX_NAME == \"YOUR_INDEX_NAME\":\n",
    "    raise ValueError(\"Set PINECONE_INDEX_NAME or replace 'YOUR_INDEX_NAME' with an existing index name.\")\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# Demo content to upsert and query\n",
    "TEXTS = [\n",
    "    \"Pinecone is a vector database built for production workloads.\",\n",
    "    \"LangChain integrates with Pinecone for semantic search use cases.\",\n",
    "    \"Async workflows let you reuse Pinecone connections efficiently.\",\n",
    "]\n",
    "METADATAS = [{\"source\": \"demo\", \"idx\": idx} for idx, _ in enumerate(TEXTS)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e8bee",
   "metadata": {},
   "source": [
    "### Demo Content\n",
    "The snippets in `TEXTS` act as stand-ins for your own documents. Feel free to replace them with any list of strings and matching metadata before running the demos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0bd557",
   "metadata": {},
   "source": [
    "## Create Pinecone Index\n",
    "A Pinecone index is a data structure that stores vector embeddings and allows for efficient similarity search. Before you can store or query embeddings, you need to create an index with the appropriate configuration (such as dimension and metric).\n",
    "\n",
    "The following code will connect to Pinecone using your API key, check if an index with the specified name exists, and create it if necessary. This step is essential for managing and querying your vector data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99b67979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pinecone classes and utilities for index management\n",
    "from pinecone import ServerlessSpec, Pinecone\n",
    "\n",
    "# Initialize Pinecone client\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Define serverless deployment specification (cloud provider and region)\n",
    "spec = ServerlessSpec(\n",
    "    cloud=\"aws\",\n",
    "    region=\"us-west-2\",  # You can change region as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7d0eda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: clean up a previous run by deleting the index.\n",
    "# Uncomment the line below if you want to recreate the index from scratch.\n",
    "# pc.delete_index(INDEX_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f906f9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'dotproduct',\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "index_name = INDEX_NAME\n",
    "# List all existing indexes in your Pinecone project\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "# Check if the index already exists; if not, create it\n",
    "if index_name not in existing_indexes:\n",
    "    # Create a new index with specified dimension and metric\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=1536,  # Must match embedding output size\n",
    "        metric=\"dotproduct\",  # Similarity metric\n",
    "        spec=spec,\n",
    "    )\n",
    "    # Wait for the index to be ready before proceeding\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "# Connect to the index for further operations\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# View index statistics to confirm connection\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432ecad3",
   "metadata": {},
   "source": [
    "## Scenario 1 – Use `async with` (no explicit close)\n",
    "The context manager keeps a single client session open for the duration of the block and then closes it automatically when the block exits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c0a6e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_with_demo() -> None:\n",
    "    \"\"\"Demonstrate the async context manager to reuse a single Pinecone session.\"\"\"\n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding=embedding,\n",
    "        namespace=\"async-demo\",\n",
    "    )\n",
    "\n",
    "    print(\"Entering 'async with' block — a single aiohttp session backs all operations.\")\n",
    "    async with vectorstore:\n",
    "        ids = await vectorstore.aadd_texts(TEXTS, metadatas=METADATAS)\n",
    "        print(f\"Upserted {len(ids)} vectors\")\n",
    "\n",
    "        print(\"First similarity search inside the context.\")\n",
    "        results = await vectorstore.asimilarity_search(\"pinecone async\", k=2)\n",
    "        for doc in results:\n",
    "            print(f\"  {doc.id}: {doc.page_content} -> {doc.metadata}\")\n",
    "\n",
    "        print(\"Second similarity search reuses the same session (no reconnect).\")\n",
    "        extra = await vectorstore.asimilarity_search(\"LangChain\", k=1)\n",
    "        for doc in extra:\n",
    "            print(f\"  {doc.id}: {doc.page_content} -> {doc.metadata}\")\n",
    "\n",
    "        await vectorstore.adelete(ids=ids)\n",
    "        print(\"Cleaned up vectors while still inside the context.\")\n",
    "\n",
    "    print(\"Context exited — session closed automatically.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e70a1f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering 'async with' block — a single aiohttp session backs all operations.\n",
      "Upserted 3 vectors\n",
      "First similarity search inside the context.\n",
      "Second similarity search reuses the same session (no reconnect).\n",
      "Cleaned up vectors while still inside the context.\n",
      "Context exited — session closed automatically.\n"
     ]
    }
   ],
   "source": [
    "# Run the async-context-manager demo\n",
    "await async_with_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e34504c",
   "metadata": {},
   "source": [
    "## Scenario 2 – Sequential calls without a context manager\n",
    "Even without `async with`, the vector store now rebuilds the async client whenever a previous session has been closed. The loop below runs multiple add/search/delete cycles back-to-back without calling `aclose()` manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5772f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def automatic_refresh_demo() -> None:\n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding=embedding,\n",
    "        namespace=\"auto-refresh-demo\",\n",
    "    )\n",
    "\n",
    "    for run in range(2):\n",
    "        print(f\"Run {run + 1}: adding texts without an outer context manager.\")\n",
    "        payload = [f\"Pinecone auto refresh demo {run}\"]\n",
    "        metadata = [{\"source\": \"auto\", \"run\": run}]\n",
    "        ids = await vectorstore.aadd_texts(payload, metadatas=metadata)\n",
    "        print(f\"  Upserted ids: {ids}\")\n",
    "\n",
    "        results = await vectorstore.asimilarity_search(\"pinecone\", k=1)\n",
    "        for doc in results:\n",
    "            print(f\"  Search hit: {doc.page_content} -> {doc.metadata}\")\n",
    "\n",
    "        await vectorstore.adelete(ids=ids)\n",
    "        print(\"  Deleted vectors; the next loop iteration will reopen a fresh session automatically.\")\n",
    "\n",
    "    print(\"Finished sequential runs without ever calling aclose().\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97627038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1: adding texts without an outer context manager.\n",
      "  Upserted ids: ['62ac61ed-f228-4514-8925-60a54d090d24']\n",
      "  Deleted vectors; the next loop iteration will reopen a fresh session automatically.\n",
      "Run 2: adding texts without an outer context manager.\n",
      "  Upserted ids: ['c177be63-b003-4fe3-9c39-5138524dbf20']\n",
      "  Deleted vectors; the next loop iteration will reopen a fresh session automatically.\n",
      "Finished sequential runs without ever calling aclose().\n"
     ]
    }
   ],
   "source": [
    "# Run the sequential demo without an explicit context manager\n",
    "await automatic_refresh_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4af4c5",
   "metadata": {},
   "source": [
    "## Scenario 3 – Explicitly close the async session\n",
    "Call `await store.aclose()` when you want deterministic cleanup after a set of operations (for example before handing the store to another task). The store can still be reused afterwards because it will lazily build a new session on the next async call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70455074",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def manual_close_demo() -> None:\n",
    "    \"\"\"Show explicit lifecycle management with aclose().\"\"\"\n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding=embedding,\n",
    "        namespace=\"manual-demo\",\n",
    "    )\n",
    "\n",
    "    ids = await vectorstore.aadd_texts(TEXTS[:1], metadatas=METADATAS[:1])\n",
    "    print(f\"Added initial ids: {ids}\")\n",
    "    try:\n",
    "        results = await vectorstore.asimilarity_search(\"pinecone\", k=1)\n",
    "        for doc in results:\n",
    "            print(f\"  Search hit: {doc.page_content} -> {doc.metadata}\")\n",
    "    finally:\n",
    "        await vectorstore.adelete(ids=ids)\n",
    "        print(\"Deleted initial vectors; calling aclose() to release the session.\")\n",
    "        await vectorstore.aclose()\n",
    "\n",
    "    print(\"Session closed. The next call recreates the client lazily.\")\n",
    "    follow_up_metadata = [{\"source\": \"manual\", \"stage\": \"follow-up\"}]\n",
    "    follow_up_ids = await vectorstore.aadd_texts(TEXTS[1:2], metadatas=follow_up_metadata)\n",
    "    print(f\"Added follow-up ids: {follow_up_ids}\")\n",
    "    try:\n",
    "        follow_up_results = await vectorstore.asimilarity_search(\"langchain\", k=1)\n",
    "        for doc in follow_up_results:\n",
    "            print(f\"  Follow-up hit: {doc.page_content} -> {doc.metadata}\")\n",
    "    finally:\n",
    "        await vectorstore.adelete(ids=follow_up_ids)\n",
    "        await vectorstore.aclose()\n",
    "        print(\"Explicit close called again to tidy up.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd9451d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added initial ids: ['3420a3ab-22d4-456a-8f70-340f29383896']\n",
      "Deleted initial vectors; calling aclose() to release the session.\n",
      "Session closed. The next call recreates the client lazily.\n",
      "Added follow-up ids: ['0fb7b67d-15b2-4dfd-b4cf-e6c248f845f1']\n",
      "Explicit close called again to tidy up.\n"
     ]
    }
   ],
   "source": [
    "# Run the explicit close demo\n",
    "await manual_close_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433d193c",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Replace the demo texts and metadata with your own dataset to mirror production behaviour.\n",
    "- `async with PineconeVectorStore(...)` keeps one HTTP session open across the block and closes it automatically on exit.\n",
    "- Without an `async with` block, each call now reinitialises the session whenever the previous one has been closed, so you can run back-to-back async operations safely.\n",
    "- `await store.aclose()` is still useful when you want deterministic cleanup between batches or before handing the store to another component.\n",
    "- If you run these cells multiple times, consider changing the namespace or cleaning up vectors to avoid duplicate data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pine-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
